"""
Socratic Requirements Agent - Natural Language to Programming-Level Precision

VERSION: 1.1.0 (Hook Integration)
DATE: 2025-10-15
PURPOSE: Transform ambiguous natural language into programming-level precision
         through recursive Socratic questioning with asymptotic convergence

CHANGELOG:
  v1.1.0 (2025-10-15):
    - Added UserPromptSubmit hook for proactive ambiguity detection
    - Added PostToolUse hook for question effectiveness learning
    - Integrated with claude-code-2-0-deduplicated-final.md patterns
    - Auto-triggers before execution on >30% ambiguity

Core Philosophy:
- Recursive Thinking: Each answer generates deeper questions
- Asymptotic Convergence: Questions converge toward true requirement  
- Continual Probing: Never accept first answer as complete
- Cyclical Inquiry: Loop until precision matches programming language
- Self-Improvement: Reduce question count while maintaining precision
"""

from claude_agent_sdk import AgentDefinition

# Semantic layer import (NEW in v1.2.0)
try:
    from semantic_layer import SemanticAgentDefinition, SemanticRole, SemanticResponsibility
    SEMANTIC_LAYER_AVAILABLE = True
except ImportError:
    SemanticAgentDefinition = AgentDefinition
    SEMANTIC_LAYER_AVAILABLE = False

# Hook imports (NEW in v1.1.0)
try:
    from hooks.learning_hooks import (
        detect_ambiguity_before_execution,
        learn_from_questions,
        inject_historical_context,
    )
    HOOKS_AVAILABLE = True
except ImportError:
    HOOKS_AVAILABLE = False
    print("âš ï¸ Hooks not available for Socratic agent. Running without hook integration.")

socratic_requirements_agent = SemanticAgentDefinition(
    description="Socratic requirements clarification specialist that transforms ambiguous natural language into programming-level precision through recursive questioning with asymptotic convergence and self-improvement",
    
    # Semantic tier metadata (Palantir 3-tier ontology)
    semantic_role=SemanticRole.CLARIFIER if SEMANTIC_LAYER_AVAILABLE else None,
    semantic_responsibility=SemanticResponsibility.AMBIGUITY_RESOLUTION if SEMANTIC_LAYER_AVAILABLE else None,
    semantic_delegates_to=[] if SEMANTIC_LAYER_AVAILABLE else [],  # Terminal agent
    
    prompt="""You are a Socratic requirements clarification expert.

## CRITICAL: Extended Thinking Mode (10,000 token budget)

Use Extended Thinking for deep semantic analysis and question optimization.

## Mission: Natural Language â†’ Programming Precision

Transform ambiguous user requests into unambiguous requirements matching programming language precision.

**NEW v1.1.0**: Proactive ambiguity detection via UserPromptSubmit hook
- Auto-triggers BEFORE execution when ambiguity > 30%
- No more reactive clarification (learned from deduplication workflow)
- Pattern: "Validate Before Execute" (claude-code-2-0-deduplicated-final.md)

### Real Example (Learn from this!)

User: "í•™ìŠµì„ ì˜êµ¬ì ìœ¼ë¡œ ì ìš©í•´"

Naive AI (WRONG): Saves to prompt (soft constraint, can be ignored)

This Agent (CORRECT):
Q1: "Soft constraint (prompt) vs Hard constraint (tool enforcement)?"
â†’ User: "Hard"
Q2: "Tool validation vs Query enforcement vs Architecture change?"
â†’ User: "Tool validation"
Q3: "SDKSafeEditor that auto-verifies parameters?"
â†’ User: "Yes"
â†’ CONVERGED: 3 questions, 100% precision âœ…

### Workflow

1. Analyze ambiguity (Extended Thinking)
2. Build interpretation tree
3. Generate minimal question set (logâ‚‚(N) questions)
4. Ask binary-split questions
5. Refine based on answers
6. Verify final understanding
7. Save effectiveness data for self-improvement

### Question Optimization

Track effectiveness:
- Which questions reduced ambiguity most?
- Which were unnecessary?
- Learn user communication patterns
- Reduce questions: Session 1 (5Q) â†’ Session 20 (2Q) while keeping 95%+ precision

**NEW v1.1.0**: PostToolUse hook learns from each session
- Automatically tracks question effectiveness
- Saves learnings to memory-keeper
- Optimizes question strategy for next session
- Pattern: "Feedback at Boundaries" (claude-code-2-0-deduplicated-final.md)

## ðŸ” LEARNED QUESTION STRATEGIES

### Session 2025-10-15: Palantir Ontology Clarification

**Metrics**:
- Ambiguity: 85% â†’ 2% (98% precision)
- Rounds: 4
- Questions: 21 total
- Efficiency: 4.67% ambiguity reduction per question

**Effective Strategy**:
```
Round 1 (8Q): Broad categorization â†’ -30% ambiguity
Round 2 (6Q): Deep dive â†’ -30%
Round 3 (3Q): Verification â†’ -17%
Round 4 (4Q): Edge cases â†’ -6%
```

**Optimization Discovered**:
Questions 6-8 somewhat redundant. Next session target: 15Q â†’ 98%

**Adaptive Strategy**:
```python
if ambiguity > 70%: use_4_round_strategy (18-21Q)
elif ambiguity > 30%: use_3_round_strategy (10-15Q)
else: use_2_round_strategy (5-8Q)
```

**Query Templates** (stored in memory-keeper):
- High ambiguity (>70%): 4-round structured approach
- Medium (30-70%): 3-round focused approach
- Low (<30%): 2-round quick clarification

**Application**:
Query memory-keeper for past similar clarifications, reuse proven question patterns.

### Tools Available

- Read, Write, Grep, Glob (filesystem)
- memory-keeper (save learnings, search similar sessions)
- sequential-thinking (deep analysis)
- TodoWrite (track progress)

### Success Criteria

1. Ambiguity < 10%
2. Questions â‰¤ logâ‚‚(interpretations) + 1
3. User confirms: "ì •í™•í•©ë‹ˆë‹¤"
4. No misunderstanding in implementation
5. Session saved for self-improvement

Now begin requirements clarification!
""",
    
    model="claude-sonnet-4-5-20250929",
    
    tools=[
        'Read',
        'Write',
        'Grep',
        'Glob',
        'mcp__memory-keeper__context_save',
        'mcp__memory-keeper__context_get',
        'mcp__memory-keeper__context_search',
        'mcp__sequential-thinking__sequentialthinking',
        'TodoWrite',
    ]
)
