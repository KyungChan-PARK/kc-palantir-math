# Code Review: Potential Issues Report

**Date**: 2025-10-16
**Scope**: Memory management, resource leaks, connection handling
**Reviewed Files**: 9 core system files
**Severity Levels**: CRITICAL, HIGH, MEDIUM, LOW

---

## Executive Summary

ì½”ë“œë² ì´ìŠ¤ ê²€í†  ê²°ê³¼ **15ê°œì˜ ì ì¬ì  issues**ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤:
- **CRITICAL**: 2ê°œ (Neo4j connection pool ê³ ê°ˆ, Meta-orchestrator registry ëˆ„ìˆ˜)
- **HIGH**: 4ê°œ (Cleanup mechanism ë¶€ì¬, Driver ê´€ë¦¬, Playwright ëˆ„ìˆ˜)
- **MEDIUM**: 7ê°œ (History growth, HTTP client, Event loop)
- **LOW**: 2ê°œ (Global state, nest_asyncio)

**ê°€ì¥ ê¸´ê¸‰í•œ ìˆ˜ì • í•„ìš”**: Neo4j connection management, Meta-orchestrator cleanup

---

## CRITICAL Issues

### Issue #1: Neo4j Connection Pool Exhaustion
**File**: `tools/neo4j_client.py`
**Lines**: 78-100, 110-126, 134-148 (ëª¨ë“  ì¿¼ë¦¬ ë©”ì„œë“œ)
**Severity**: âš ï¸ **CRITICAL**

**ë¬¸ì œ**:
```python
def query_prerequisites(self, concept_id: str, max_depth: int = 5):
    with self.driver.session(database=self.database) as session:
        result = session.run(...)
        return [dict(record) for record in result]  # âŒ ì—¬ê¸°ì„œ ì˜ˆì™¸ ë°œìƒ ì‹œ?
```

- ê° ë©”ì„œë“œê°€ ìƒˆ ì„¸ì…˜ì„ ìƒì„±
- `dict(record)` ë³€í™˜ ì¤‘ ì˜ˆì™¸ ë°œìƒ ì‹œ ì„¸ì…˜ì´ ì œëŒ€ë¡œ ì •ë¦¬ ì•ˆ ë  ìˆ˜ ìˆìŒ
- Connection poolì—ì„œ ì„¸ì…˜ì´ ë°˜í™˜ë˜ì§€ ì•ŠìŒ

**ì˜í–¥**:
- Long-running sessionsì—ì„œ connection pool ê³ ê°ˆ
- `Neo4jError: Failed to obtain connection from pool within configured maximum time`
- ì‹œìŠ¤í…œ ì „ì²´ ì •ì§€ ê°€ëŠ¥

**ìˆ˜ì • ë°©ì•ˆ**:
```python
def query_prerequisites(self, concept_id: str, max_depth: int = 5):
    with self.driver.session(database=self.database) as session:
        result = session.run(...)
        # âœ… ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ë‚´ì—ì„œ ë³€í™˜ ì™„ë£Œ
        records = [dict(record) for record in result]
    return records  # ì„¸ì…˜ ì •ë¦¬ í›„ ë°˜í™˜
```

**ìš°ì„ ìˆœìœ„**: ğŸ”´ **IMMEDIATE**

---

### Issue #2: Meta-Orchestrator Unbounded Registry Growth
**File**: `agents/meta_orchestrator.py`
**Lines**: 1599-1607, 1621-1629
**Severity**: âš ï¸ **CRITICAL**

**ë¬¸ì œ**:
```python
# Line 1599-1607
if not hasattr(self, '_semantic_registry'):
    self._semantic_registry = {
        'agents': {},
        'tools': {},
        'hooks': {},
        'capabilities_index': {}
    }
    # Auto-register all current agents
    self._register_all_discovered_agents()

# Line 1621-1629 (register_agent)
self._semantic_registry['agents'][agent_name] = {
    'definition': agent_def,
    'capabilities': caps,
    'tools': agent_def.tools if hasattr(agent_def, 'tools') else [],
    'registered_at': datetime.now().isoformat()
}
# âŒ ì œê±° ë©”ì»¤ë‹ˆì¦˜ ì—†ìŒ
```

**ì˜í–¥**:
- `_semantic_registry`ê°€ ê³„ì† ì¦ê°€ (agents, capabilities_index)
- 100íšŒ agent ë“±ë¡ ì‹œ 100ê°œ ë”•ì…”ë„ˆë¦¬ í•­ëª© + ê° agentì˜ definition/tools ì €ì¥
- Long-running sessions (24ì‹œê°„ ì´ìƒ)ì—ì„œ ìˆ˜ë°± MB ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°€ëŠ¥

**ì¦ê±°**:
- Line 1607: `_register_all_discovered_agents()` - ë¹ˆ êµ¬í˜„ì´ì§€ë§Œ ì£¼ì„ì— "auto-register all discovered agents" ëª…ì‹œ
- Line 1621-1629: `register_agent`ê°€ ì¶”ê°€ë§Œ í•˜ê³  ì œê±°/cleanup ì—†ìŒ

**ìˆ˜ì • ë°©ì•ˆ**:
```python
def cleanup_registry(self, max_age_hours: int = 24):
    """Remove stale registry entries"""
    cutoff = datetime.now() - timedelta(hours=max_age_hours)

    stale_agents = [
        name for name, meta in self._semantic_registry['agents'].items()
        if datetime.fromisoformat(meta['registered_at']) < cutoff
    ]

    for agent_name in stale_agents:
        del self._semantic_registry['agents'][agent_name]
        # Remove from capabilities index
        for cap_list in self._semantic_registry['capabilities_index'].values():
            if agent_name in cap_list:
                cap_list.remove(agent_name)
```

**ìš°ì„ ìˆœìœ„**: ğŸ”´ **IMMEDIATE**

---

## HIGH Severity Issues

### Issue #3: No Cleanup Mechanism in MetaOrchestratorLogic
**File**: `agents/meta_orchestrator.py`
**Lines**: 945-1873 (entire class)
**Severity**: ğŸŸ  **HIGH**

**ë¬¸ì œ**:
```python
class MetaOrchestratorLogic:
    def __init__(self):
        self.agent_registry = {}
        self.consecutive_failures = {}
        self._kinetic_tier = None
        self._dynamic_tier = None
        self._semantic_tier = None

    # âŒ __del__, cleanup(), close() ë©”ì„œë“œ ì—†ìŒ
```

**ì˜í–¥**:
- Tier objects (`_kinetic_tier`, `_dynamic_tier`, `_semantic_tier`)ê°€ ì •ë¦¬ë˜ì§€ ì•ŠìŒ
- ê° tierê°€ ìì²´ state/resourcesë¥¼ ê°€ì§ (HTTP clients, event loops ë“±)
- ëª…ì‹œì  ë¦¬ì†ŒìŠ¤ í•´ì œ ë¶ˆê°€ëŠ¥

**ìˆ˜ì • ë°©ì•ˆ**:
```python
def cleanup(self):
    """Cleanup all tier resources"""
    if self._kinetic_tier:
        if hasattr(self._kinetic_tier, 'cleanup'):
            self._kinetic_tier.cleanup()
        self._kinetic_tier = None

    if self._dynamic_tier:
        # Cleanup dynamic tier resources
        self._dynamic_tier = None

    if self._semantic_tier:
        # Cleanup semantic tier resources
        self._semantic_tier = None

    # Clear registries
    self.agent_registry.clear()
    self.consecutive_failures.clear()
    if hasattr(self, '_semantic_registry'):
        self._semantic_registry['agents'].clear()
        self._semantic_registry['tools'].clear()
        self._semantic_registry['hooks'].clear()
        self._semantic_registry['capabilities_index'].clear()

def __del__(self):
    """Destructor - ensure cleanup on GC"""
    self.cleanup()
```

**ìš°ì„ ìˆœìœ„**: ğŸŸ  **HIGH**

---

### Issue #4: Neo4j Driver Not Closed in Production Code
**File**: `agents/neo4j_query_agent.py`
**Lines**: 227-234 (example code only)
**Severity**: ğŸŸ  **HIGH**

**ë¬¸ì œ**:
```python
# Line 227-234 (example in prompt)
from tools.neo4j_client import Neo4jConceptGraphClient

client = Neo4jConceptGraphClient()
client.connect()

result = client.query_prerequisites(...)

client.close()  # âœ… ì˜ˆì œì—ëŠ” ìˆì§€ë§Œ ì‹¤ì œ production ì½”ë“œì—ëŠ”?
```

- Promptì— ì˜ˆì œë§Œ ìˆê³  ì‹¤ì œ agent logicì—ëŠ” close() í˜¸ì¶œ ë³´ì¥ ì•ˆ ë¨
- Context manager ì‚¬ìš© ê¶Œì¥í•˜ì§€ë§Œ enforcedë˜ì§€ ì•ŠìŒ

**ìˆ˜ì • ë°©ì•ˆ**:
```python
# neo4j_query_agent promptì— ê°•ì œ
"""
MANDATORY: Always use context manager for Neo4j client

# âœ… CORRECT
with Neo4jConceptGraphClient() as client:
    result = client.query_prerequisites(...)

# âŒ WRONG - Connection leak
client = Neo4jConceptGraphClient()
client.connect()
result = client.query_prerequisites(...)
# Forgot to close()
"""
```

**ìš°ì„ ìˆœìœ„**: ğŸŸ  **HIGH**

---

### Issue #5: Playwright Browser Instance Leak
**File**: `agents/runtime_mixins.py`
**Lines**: 187-188, 259-262
**Severity**: ğŸŸ  **HIGH** (if computer_use enabled)

**ë¬¸ì œ**:
```python
# Line 187-188
if not executor:
    from integrations.computer_use.playwright_executor import PlaywrightExecutor
    executor = PlaywrightExecutor()  # âŒ ìƒˆ browser instance ìƒì„±

# Line 259-262
cu_mixin = ComputerUseMixin()
agent_definition._computer_use = cu_mixin
agent_definition.enable_computer_use = cu_mixin.enable_computer_use
# âŒ cu_mixinì˜ executor cleanup ë©”ì»¤ë‹ˆì¦˜ ì—†ìŒ
```

**ì˜í–¥**:
- ê° agent enhancement ì‹œ ìƒˆ PlaywrightExecutor (Chromium instance) ìƒì„±
- Browser processesê°€ ì¢…ë£Œë˜ì§€ ì•ŠìŒ
- 10ë²ˆ enhancement í›„ 10ê°œì˜ Chromium processes ëˆ„ìˆ˜

**ìˆ˜ì • ë°©ì•ˆ**:
```python
class ComputerUseMixin:
    def __init__(self):
        self._computer_use_adapter = None
        self._computer_use_enabled = False
        self._executor = None  # Track executor

    def cleanup(self):
        """Cleanup Playwright executor"""
        if self._executor and hasattr(self._executor, 'close'):
            self._executor.close()
        self._executor = None
        self._computer_use_adapter = None

    def __del__(self):
        self.cleanup()
```

**ìš°ì„ ìˆœìœ„**: ğŸŸ  **HIGH** (if computer_use feature used)

---

## MEDIUM Severity Issues

### Issue #6: Unbounded History Lists in KineticLayer
**File**: `kinetic_layer.py`
**Lines**: 113, 180, 262, 287, 370, 391-396
**Severity**: ğŸŸ¡ **MEDIUM**

**ë¬¸ì œ**:
```python
# Line 113, 180
self.execution_history: List[ExecutionResult] = []
self.execution_history.append(result)  # âŒ ê³„ì† ì¦ê°€

# Line 262, 287
self.data_flows: List[Dict] = []
self.data_flows.append(flow)  # âŒ ê³„ì† ì¦ê°€

# Line 370, 391-396
self.state_history: List[tuple] = []
self.state_history.append((current, new, time, reason))  # âŒ ê³„ì† ì¦ê°€
```

**ì˜í–¥**:
- Long-running workflowsì—ì„œ ë©”ëª¨ë¦¬ ì¦ê°€
- 1000íšŒ workflow ì‹¤í–‰ ì‹œ 1000ê°œ ExecutionResult objects ëˆ„ì 

**ìˆ˜ì • ë°©ì•ˆ**:
```python
def __init__(self, max_history: int = 1000):
    self.execution_history: List[ExecutionResult] = []
    self.max_history = max_history

# When appending
self.execution_history.append(result)
if len(self.execution_history) > self.max_history:
    # Keep only recent N
    self.execution_history = self.execution_history[-self.max_history:]
```

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ **MEDIUM**

---

### Issue #7: Inefficient Event Loop Creation
**File**: `agents/meta_orchestrator.py`
**Lines**: 1575-1581
**Severity**: ğŸŸ¡ **MEDIUM**

**ë¬¸ì œ**:
```python
def orchestrate_kinetic(self, task: str, agents: List[str], context: Dict[str, Any]):
    # ...
    import asyncio
    result = asyncio.run(self._kinetic_tier.execute_task(task, agents, context))
    # âŒ ë§¤ë²ˆ ìƒˆë¡œìš´ event loop ìƒì„±/ì‚­ì œ
```

**ì˜í–¥**:
- ë§¤ í˜¸ì¶œë§ˆë‹¤ event loop overhead
- ë©”ëª¨ë¦¬ ë‹¨í¸í™” ê°€ëŠ¥
- ì„±ëŠ¥ ì €í•˜ (loop ìƒì„±/ì‚­ì œ ë¹„ìš©)

**ìˆ˜ì • ë°©ì•ˆ**:
```python
def orchestrate_kinetic(self, task: str, agents: List[str], context: Dict[str, Any]):
    # Use existing event loop if available
    try:
        loop = asyncio.get_running_loop()
        # Create task instead
        task_obj = loop.create_task(
            self._kinetic_tier.execute_task(task, agents, context)
        )
        result = loop.run_until_complete(task_obj)
    except RuntimeError:
        # No running loop, create one
        result = asyncio.run(self._kinetic_tier.execute_task(task, agents, context))

    return {...}
```

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ **MEDIUM**

---

### Issue #8: HTTP Client Connection Pool Not Managed
**File**: `agents/meta_orchestrator.py`
**Lines**: 1789-1800
**Severity**: ğŸŸ¡ **MEDIUM**

**ë¬¸ì œ**:
```python
def _query_observability_events(self, session_id: str) -> list:
    try:
        import httpx
        response = httpx.get(
            f"http://localhost:4000/events/recent?session_id={session_id}&limit=1000",
            timeout=5
        )  # âŒ Connection pool ê´€ë¦¬ ì•ˆ ë¨
```

**ì˜í–¥**:
- ê° í˜¸ì¶œë§ˆë‹¤ ìƒˆ HTTP connection
- Connection poolì´ ì¬ì‚¬ìš©ë˜ì§€ ì•ŠìŒ
- ì†Œì¼“ ê³ ê°ˆ ê°€ëŠ¥ (ë§ì€ í˜¸ì¶œ ì‹œ)

**ìˆ˜ì • ë°©ì•ˆ**:
```python
def __init__(self):
    # ...
    self._http_client = None

@property
def http_client(self):
    if self._http_client is None:
        import httpx
        self._http_client = httpx.Client(timeout=5)
    return self._http_client

def _query_observability_events(self, session_id: str) -> list:
    try:
        response = self.http_client.get(...)
    except:
        pass
    return []

def cleanup(self):
    if self._http_client:
        self._http_client.close()
```

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ **MEDIUM**

---

### Issue #9: Agent Enhancement Without Cleanup
**File**: `main.py`
**Lines**: 125-129
**Severity**: ğŸŸ¡ **MEDIUM**

**ë¬¸ì œ**:
```python
# Line 125-129
if runtime_config['observability_enabled']:
    for agent_name, agent in discovered_agents.items():
        if hasattr(agent, 'enable_observability'):
            agent.enable_observability(global_session_id, source_app=f"math-{agent_name}")
    # âŒ ì´ agentsê°€ cleanupë˜ì§€ ì•ŠìŒ
```

**ì˜í–¥**:
- ê° agentì— `_obs` mixin attached
- EventReporter instances ëˆ„ì 
- ì—¬ëŸ¬ ì„¸ì…˜ ì‹¤í–‰ ì‹œ ê°„ì„­ ê°€ëŠ¥

**ìˆ˜ì • ë°©ì•ˆ**:
```python
# Add cleanup before exit
def cleanup_agents():
    for agent_name, agent in discovered_agents.items():
        if hasattr(agent, 'cleanup'):
            agent.cleanup()

# In main loop
try:
    # ... conversation loop ...
finally:
    cleanup_agents()
    if obs_reporter:
        obs_reporter.session_end(global_session_id)
```

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ **MEDIUM**

---

### Issue #10: Runtime Integration Resources Not Cleaned
**File**: `kinetic_layer.py`
**Lines**: 30-38
**Severity**: ğŸŸ¡ **MEDIUM**

**ë¬¸ì œ**:
```python
# Line 30-38
try:
    from integrations.observability.event_reporter import EventReporter
    from integrations.realtime.gateway_service import RealtimeGateway
    from integrations.computer_use.playwright_executor import PlaywrightExecutor
    RUNTIME_AVAILABLE = True
except ImportError:
    RUNTIME_AVAILABLE = False
```

**ì˜í–¥**:
- ì´ ê°ì²´ë“¤ì´ ì–´ë””ì„ ê°€ instantiateë˜ë©´ cleanup ì•ˆ ë¨
- WebSocket connections, HTTP clients, browser instances ëˆ„ìˆ˜ ê°€ëŠ¥

**ìˆ˜ì • ë°©ì•ˆ**:
KineticTierì— cleanup ë©”ì„œë“œ ì¶”ê°€:
```python
class KineticTier:
    def __init__(self):
        # ...
        self._runtime_resources = []

    def cleanup(self):
        """Cleanup runtime integration resources"""
        for resource in self._runtime_resources:
            if hasattr(resource, 'close'):
                resource.close()
            elif hasattr(resource, 'cleanup'):
                resource.cleanup()
        self._runtime_resources.clear()
```

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ **MEDIUM**

---

### Issue #11: Mixin Instances Without Cleanup
**File**: `agents/runtime_mixins.py`
**Lines**: 240-263
**Severity**: ğŸŸ¡ **MEDIUM**

**ë¬¸ì œ**:
```python
# Line 240-263
if 'observability' in features:
    obs_mixin = ObservabilityMixin()
    agent_definition._obs = obs_mixin  # âŒ cleanup ë©”ì»¤ë‹ˆì¦˜ ì—†ìŒ

if 'realtime' in features:
    rt_mixin = RealtimeMixin()
    agent_definition._realtime = rt_mixin  # âŒ cleanup ë©”ì»¤ë‹ˆì¦˜ ì—†ìŒ

if 'computer_use' in features:
    cu_mixin = ComputerUseMixin()
    agent_definition._computer_use = cu_mixin  # âŒ cleanup ë©”ì»¤ë‹ˆì¦˜ ì—†ìŒ
```

**ìˆ˜ì • ë°©ì•ˆ**:
```python
def enhance_agent(...):
    # ... existing code ...

    # Add cleanup method to agent
    def cleanup_enhanced_agent():
        if hasattr(agent_definition, '_obs'):
            agent_definition._obs = None
        if hasattr(agent_definition, '_realtime'):
            if hasattr(agent_definition._realtime, 'cleanup'):
                agent_definition._realtime.cleanup()
            agent_definition._realtime = None
        if hasattr(agent_definition, '_computer_use'):
            if hasattr(agent_definition._computer_use, 'cleanup'):
                agent_definition._computer_use.cleanup()
            agent_definition._computer_use = None

    agent_definition.cleanup = cleanup_enhanced_agent
    return agent_definition
```

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ **MEDIUM**

---

### Issue #12: No Global Cleanup Coordinator
**File**: ì „ì²´ ì‹œìŠ¤í…œ (cross-cutting concern)
**Severity**: ğŸŸ¡ **MEDIUM**

**ë¬¸ì œ**:
- ê° ì»´í¬ë„ŒíŠ¸ê°€ ë…ë¦½ì ìœ¼ë¡œ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬
- ì‹œìŠ¤í…œ ì „ì²´ shutdown ì‹œ ì¡°ìœ¨ëœ cleanup ì—†ìŒ
- main.py ì¢…ë£Œ ì‹œ ë¦¬ì†ŒìŠ¤ ëˆ„ìˆ˜ ê°€ëŠ¥

**ìˆ˜ì • ë°©ì•ˆ**:
```python
# cleanup_coordinator.py
class CleanupCoordinator:
    """Coordinate system-wide cleanup on shutdown"""

    def __init__(self):
        self.cleanup_callbacks = []

    def register(self, callback: Callable):
        """Register cleanup callback"""
        self.cleanup_callbacks.append(callback)

    def cleanup_all(self):
        """Execute all cleanup callbacks"""
        for callback in reversed(self.cleanup_callbacks):  # LIFO
            try:
                callback()
            except Exception as e:
                logging.error(f"Cleanup error: {e}")

# In main.py
coordinator = CleanupCoordinator()
coordinator.register(cleanup_agents)
coordinator.register(lambda: obs_reporter.session_end(global_session_id))
coordinator.register(lambda: client.close() if hasattr(client, 'close') else None)

# On shutdown
coordinator.cleanup_all()
```

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ **MEDIUM**

---

## LOW Severity Issues

### Issue #13: Global Session State in main.py
**File**: `main.py`
**Lines**: 115-116, 122
**Severity**: ğŸŸ¢ **LOW**

**ë¬¸ì œ**:
```python
# Line 115-116
global_session_id = f"session-{session_timestamp}"
obs_reporter = EventReporter("math-system")
```

**ì˜í–¥**: ì—¬ëŸ¬ ì„¸ì…˜ ë™ì‹œ ì‹¤í–‰ ì‹œ ê°„ì„­ ê°€ëŠ¥ (í˜„ì¬ëŠ” single sessionì´ë¼ ë¬¸ì œ ì—†ìŒ)

**ìˆ˜ì • ë°©ì•ˆ**: ì„¸ì…˜ì„ classë¡œ ìº¡ìŠí™”
```python
class SessionContext:
    def __init__(self):
        self.session_id = f"session-{datetime.now().strftime('%Y%m%d-%H%M%S')}"
        self.obs_reporter = EventReporter("math-system")

    def cleanup(self):
        if self.obs_reporter:
            self.obs_reporter.session_end(self.session_id)
```

**ìš°ì„ ìˆœìœ„**: ğŸŸ¢ **LOW**

---

### Issue #14: nest_asyncio Warning
**File**: `main.py`
**Lines**: 472-473
**Severity**: ğŸŸ¢ **LOW**

**ë¬¸ì œ**:
```python
import nest_asyncio
nest_asyncio.apply()  # âš ï¸ Nested event loopsëŠ” ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ìœ ë°œ ê°€ëŠ¥
```

**ì˜í–¥**:
- Nested event loopsëŠ” ì¼ë¶€ í™˜ê²½ì—ì„œ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜
- í•˜ì§€ë§Œ ì¼ë¶€ Jupyter í™˜ê²½ì—ì„œëŠ” í•„ìˆ˜

**ìˆ˜ì • ë°©ì•ˆ**: ì¡°ê±´ë¶€ ì ìš©
```python
# Only apply if actually needed
if 'IPython' in sys.modules:
    import nest_asyncio
    nest_asyncio.apply()
```

**ìš°ì„ ìˆœìœ„**: ğŸŸ¢ **LOW**

---

## ê¶Œì¥ ìˆ˜ì • ìˆœì„œ (Priority Order)

### Phase 1: CRITICAL (1-2 days)
1. âœ… **Issue #1**: Neo4j connection pool - session management ìˆ˜ì •
2. âœ… **Issue #2**: Meta-orchestrator registry cleanup ë©”ì»¤ë‹ˆì¦˜ ì¶”ê°€

### Phase 2: HIGH (3-4 days)
3. âœ… **Issue #3**: MetaOrchestratorLogic cleanup() ë©”ì„œë“œ ì¶”ê°€
4. âœ… **Issue #4**: neo4j_query_agent context manager ê°•ì œ
5. âœ… **Issue #5**: Playwright cleanup (if computer_use enabled)

### Phase 3: MEDIUM (5-7 days)
6. âœ… **Issue #6**: KineticLayer history í¬ê¸° ì œí•œ
7. âœ… **Issue #7**: Event loop ì¬ì‚¬ìš©
8. âœ… **Issue #8**: HTTP client connection pool
9. âœ… **Issue #9**: Agent cleanup in main.py
10. âœ… **Issue #10**: Runtime integration cleanup
11. âœ… **Issue #11**: Mixin cleanup
12. âœ… **Issue #12**: Global cleanup coordinator

### Phase 4: LOW (Optional)
13. âœ… **Issue #13**: Session encapsulation
14. âœ… **Issue #14**: nest_asyncio ì¡°ê±´ë¶€ ì ìš©

---

## í…ŒìŠ¤íŠ¸ ê³„íš

### Memory Leak Tests
```python
# test_memory_leak.py
def test_meta_orchestrator_registry_cleanup():
    """Verify registry cleanup works"""
    logic = MetaOrchestratorLogic()

    # Register 100 agents
    for i in range(100):
        logic.orchestrate_semantic('register_agent',
                                   agent_definition=...,
                                   name=f"agent_{i}")

    assert len(logic._semantic_registry['agents']) == 100

    # Cleanup
    logic.cleanup_registry(max_age_hours=0)

    assert len(logic._semantic_registry['agents']) == 0

def test_neo4j_connection_cleanup():
    """Verify Neo4j sessions are closed"""
    with Neo4jConceptGraphClient() as client:
        result = client.query_prerequisites('test_concept')

    # Verify driver closed
    # (requires Neo4j driver instrumentation)
```

### Integration Tests
```python
def test_long_running_session():
    """Simulate 24-hour session"""
    # Run 1000 workflow executions
    # Monitor memory usage
    # Verify no growth beyond expected bounds
```

---

## Monitoring Recommendations

### ì¶”ê°€í•  ë©”íŠ¸ë¦­
1. **Connection Pool Size** (Neo4j)
   - `neo4j.driver.pool.size.current`
   - Alert if > 80% capacity

2. **Registry Size** (Meta-orchestrator)
   - `meta_orchestrator.registry.agents.count`
   - Alert if > 1000

3. **History List Size** (KineticLayer)
   - `kinetic.execution_history.size`
   - Alert if > 10000

4. **Browser Instances** (Playwright)
   - `playwright.browser.instances.active`
   - Alert if > 5

---

## ê²°ë¡ 

í˜„ì¬ ì½”ë“œë² ì´ìŠ¤ëŠ” **short-lived sessions (< 1 hour)**ì—ì„œëŠ” ë¬¸ì œì—†ì§€ë§Œ, **long-running sessions (24+ hours)** ë˜ëŠ” **high-throughput scenarios**ì—ì„œ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ì™€ ë¦¬ì†ŒìŠ¤ ê³ ê°ˆì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ê°€ì¥ ê¸´ê¸‰í•œ ìˆ˜ì •**:
1. Neo4j connection management (CRITICAL)
2. Meta-orchestrator registry cleanup (CRITICAL)
3. Global cleanup coordinator ì¶”ê°€ (MEDIUM but foundational)

ì´ 3ê°€ì§€ë¥¼ ë¨¼ì € ìˆ˜ì •í•˜ë©´ ì‹œìŠ¤í…œ ì•ˆì •ì„±ì´ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤.
